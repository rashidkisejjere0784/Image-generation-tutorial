{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introdction\n\nHey there, am happy to introduce a couple of tutorial notebooks to show you how to generate Images using deep learning. This is the very first notebook, I expect to create upto atleast three more of these while sharing diffent Image generation tips and ideas including (GANs and Diffusion Models). So this is the very first of the series and I will be covering the very basics of image generation and that is **auto-encoders**. so lets get to it.","metadata":{}},{"cell_type":"markdown","source":"# What are Auto Encoders ?\n\nAuto Encoders lay the foundation of image generation. they are made up of majorly the encoder and decoder. the encoder as the name says encode an image(convert an image into latent space representation of that image) and the decoder converts that particular image from it;s latent space representation back to the original image(or something close to the original image).\n\n![auto encoder](https://th.bing.com/th/id/R.ed5d36cdf7bdeca3cf4660ade4d544ae?rik=v0rvzTfPBrR58w&pid=ImgRaw&r=0)\n\nSo as illustrated in the above image, auto-encoders are quite powerful and can even be used in applications like denoising images plus also image generation. \n\nAnyways enough of the theory let's get to it ","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport re\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\nfrom tensorflow.keras.models import Model\nfrom PIL import Image\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-03T00:15:19.042559Z","iopub.execute_input":"2024-03-03T00:15:19.042906Z","iopub.status.idle":"2024-03-03T00:15:32.503093Z","shell.execute_reply.started":"2024-03-03T00:15:19.042867Z","shell.execute_reply":"2024-03-03T00:15:32.502113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = \"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba\"","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:15:32.505078Z","iopub.execute_input":"2024-03-03T00:15:32.506109Z","iopub.status.idle":"2024-03-03T00:15:32.510242Z","shell.execute_reply.started":"2024-03-03T00:15:32.506045Z","shell.execute_reply":"2024-03-03T00:15:32.509334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = 64\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:15:32.511432Z","iopub.execute_input":"2024-03-03T00:15:32.511694Z","iopub.status.idle":"2024-03-03T00:15:32.540977Z","shell.execute_reply.started":"2024-03-03T00:15:32.511671Z","shell.execute_reply":"2024-03-03T00:15:32.540236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the Data","metadata":{}},{"cell_type":"code","source":"#dataset contaiins over 200l images, will be using just the 50k for training, and 10k for testing","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:15:32.542964Z","iopub.execute_input":"2024-03-03T00:15:32.543280Z","iopub.status.idle":"2024-03-03T00:15:32.549840Z","shell.execute_reply.started":"2024-03-03T00:15:32.543255Z","shell.execute_reply":"2024-03-03T00:15:32.549171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dataset():\n    # Load the entire dataset into memory\n    X = []\n    \n    pbar = tqdm(os.listdir(data_path)[:60000])\n    for filename in pbar:\n        img_path = os.path.join(data_path, filename)\n        \n        img = Image.open(img_path).convert('RGB').resize((img_size, img_size))\n        img_array = np.asarray(img) / 255.\n        X.append(img_array)\n\n    return np.stack(X)\n\nX = load_dataset()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:15:32.550930Z","iopub.execute_input":"2024-03-03T00:15:32.551284Z","iopub.status.idle":"2024-03-03T00:22:42.669658Z","shell.execute_reply.started":"2024-03-03T00:15:32.551260Z","shell.execute_reply":"2024-03-03T00:22:42.668586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = X[:15]\n\nplt.figure(figsize = (20 , 20))\nfor i in range(15):\n    plt.subplot(5 , 5, i+1)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)\n    plt.imshow(images[i])\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:42.671079Z","iopub.execute_input":"2024-03-03T00:22:42.671484Z","iopub.status.idle":"2024-03-03T00:22:43.576810Z","shell.execute_reply.started":"2024-03-03T00:22:42.671446Z","shell.execute_reply":"2024-03-03T00:22:43.575801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = X[:50000]\ntest = X[50000:]","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:43.577969Z","iopub.execute_input":"2024-03-03T00:22:43.578291Z","iopub.status.idle":"2024-03-03T00:22:43.582792Z","shell.execute_reply.started":"2024-03-03T00:22:43.578264Z","shell.execute_reply":"2024-03-03T00:22:43.581851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:43.583963Z","iopub.execute_input":"2024-03-03T00:22:43.584329Z","iopub.status.idle":"2024-03-03T00:22:43.597104Z","shell.execute_reply.started":"2024-03-03T00:22:43.584295Z","shell.execute_reply":"2024-03-03T00:22:43.596158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create the Encoder","metadata":{}},{"cell_type":"code","source":"from keras import layers\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:43.598238Z","iopub.execute_input":"2024-03-03T00:22:43.598564Z","iopub.status.idle":"2024-03-03T00:22:43.606616Z","shell.execute_reply.started":"2024-03-03T00:22:43.598534Z","shell.execute_reply":"2024-03-03T00:22:43.605849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_input = layers.Input(\n    shape = (img_size, img_size, 3), name = \"encoder_input\"\n)\n\nx = layers.Conv2D(img_size, (3, 3), strides = 2, activation = 'relu', padding=\"same\")(\n encoder_input\n)\nx = layers.Conv2D(128, (3, 3), strides = 2, activation = 'relu', padding=\"same\")(x)\nx = layers.Conv2D(512, (3, 3), strides = 2, activation = 'relu', padding=\"same\")(x)\nlayer_shape = keras.backend.int_shape(x)\nx = layers.Flatten()(x)\nencoder_output = layers.Dense(10, name=\"encoder_output\")(x)\nencoder = Model(encoder_input, encoder_output)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:43.610754Z","iopub.execute_input":"2024-03-03T00:22:43.611094Z","iopub.status.idle":"2024-03-03T00:22:44.070931Z","shell.execute_reply.started":"2024-03-03T00:22:43.611039Z","shell.execute_reply":"2024-03-03T00:22:44.070159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:44.071893Z","iopub.execute_input":"2024-03-03T00:22:44.072150Z","iopub.status.idle":"2024-03-03T00:22:44.093314Z","shell.execute_reply.started":"2024-03-03T00:22:44.072127Z","shell.execute_reply":"2024-03-03T00:22:44.092504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_shape = layer_shape[1:]\nlayer_shape","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:44.094337Z","iopub.execute_input":"2024-03-03T00:22:44.094600Z","iopub.status.idle":"2024-03-03T00:22:44.100273Z","shell.execute_reply.started":"2024-03-03T00:22:44.094577Z","shell.execute_reply":"2024-03-03T00:22:44.099344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create the Decoder","metadata":{}},{"cell_type":"code","source":"decoder_input  = layers.Input(shape = (10,), name = \"decoder_input\")\n\nx = layers.Dense(np.prod(layer_shape))(decoder_input)\nx = layers.Reshape(layer_shape)(x)\nx = layers.Conv2DTranspose(512, (3, 3), strides = 2, activation = 'relu', padding = \"same\")(x)\nx = layers.Conv2DTranspose(128, (3, 3), strides = 2, activation = 'relu', padding = \"same\")(x)\nx = layers.Conv2DTranspose(64, (3, 3), strides = 2, activation = 'relu', padding = \"same\")(x)\n\ndecoder_output = layers.Conv2D(\n 3,\n (3, 3),\n strides = 1,\n activation=\"sigmoid\",\n padding=\"same\",\n name=\"decoder_output\"\n)(x)\n\n\ndecoder = Model(decoder_input, decoder_output)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:44.101479Z","iopub.execute_input":"2024-03-03T00:22:44.101838Z","iopub.status.idle":"2024-03-03T00:22:44.153079Z","shell.execute_reply.started":"2024-03-03T00:22:44.101808Z","shell.execute_reply":"2024-03-03T00:22:44.152315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:44.154078Z","iopub.execute_input":"2024-03-03T00:22:44.154390Z","iopub.status.idle":"2024-03-03T00:22:44.175762Z","shell.execute_reply.started":"2024-03-03T00:22:44.154366Z","shell.execute_reply":"2024-03-03T00:22:44.174872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combine the two Models","metadata":{}},{"cell_type":"code","source":"autoencoder = Model(encoder_input, decoder(encoder_output))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:44.176801Z","iopub.execute_input":"2024-03-03T00:22:44.177090Z","iopub.status.idle":"2024-03-03T00:22:44.185375Z","shell.execute_reply.started":"2024-03-03T00:22:44.177043Z","shell.execute_reply":"2024-03-03T00:22:44.184519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:44.186512Z","iopub.execute_input":"2024-03-03T00:22:44.186796Z","iopub.status.idle":"2024-03-03T00:22:44.210764Z","shell.execute_reply.started":"2024-03-03T00:22:44.186771Z","shell.execute_reply":"2024-03-03T00:22:44.209909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def root_mean_squared_error(y_true, y_pred):\n    return keras.backend.sqrt(keras.backend.mean(keras.backend.square(y_pred - y_true)))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:44.211851Z","iopub.execute_input":"2024-03-03T00:22:44.212196Z","iopub.status.idle":"2024-03-03T00:22:44.217012Z","shell.execute_reply.started":"2024-03-03T00:22:44.212164Z","shell.execute_reply":"2024-03-03T00:22:44.216101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.compile(optimizer=\"adam\", loss=root_mean_squared_error)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:44.218113Z","iopub.execute_input":"2024-03-03T00:22:44.218498Z","iopub.status.idle":"2024-03-03T00:22:44.235323Z","shell.execute_reply.started":"2024-03-03T00:22:44.218467Z","shell.execute_reply":"2024-03-03T00:22:44.234299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the autoencoder\nautoencoder.fit(\n    train,\n    train,\n    epochs=15,\n    shuffle=True,\n    validation_data = (test, test)\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:22:44.236501Z","iopub.execute_input":"2024-03-03T00:22:44.237097Z","iopub.status.idle":"2024-03-03T00:32:19.156668Z","shell.execute_reply.started":"2024-03-03T00:22:44.237064Z","shell.execute_reply":"2024-03-03T00:32:19.155549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test the Model","metadata":{}},{"cell_type":"code","source":"predictions = autoencoder.predict(test)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:33:15.486427Z","iopub.execute_input":"2024-03-03T00:33:15.487090Z","iopub.status.idle":"2024-03-03T00:33:19.611147Z","shell.execute_reply.started":"2024-03-03T00:33:15.487042Z","shell.execute_reply":"2024-03-03T00:33:19.610279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = test[:15]\n\nplt.figure(figsize = (20 , 20))\nfor i in range(15):\n    plt.subplot(5 , 5, i+1)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)\n    plt.imshow(images[i])\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:52:51.550552Z","iopub.execute_input":"2024-03-03T00:52:51.550895Z","iopub.status.idle":"2024-03-03T00:52:52.151023Z","shell.execute_reply.started":"2024-03-03T00:52:51.550869Z","shell.execute_reply":"2024-03-03T00:52:52.150082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = predictions[:15]\n\nplt.figure(figsize = (20 , 20))\nfor i in range(15):\n    plt.subplot(5 , 5, i+1)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.3)\n    plt.imshow(images[i])\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:53:16.541328Z","iopub.execute_input":"2024-03-03T00:53:16.542216Z","iopub.status.idle":"2024-03-03T00:53:17.121529Z","shell.execute_reply.started":"2024-03-03T00:53:16.542174Z","shell.execute_reply":"2024-03-03T00:53:17.120548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# try to generate from random noise\nnoise_array = np.random.uniform(-2., 2., (1, 10)).astype('float32')\nprint(noise_array)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T01:03:40.784243Z","iopub.execute_input":"2024-03-03T01:03:40.784622Z","iopub.status.idle":"2024-03-03T01:03:40.791043Z","shell.execute_reply.started":"2024-03-03T01:03:40.784590Z","shell.execute_reply":"2024-03-03T01:03:40.789999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = decoder.predict(noise_array)\n\nplt.imshow((pred[0]))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T01:03:43.422960Z","iopub.execute_input":"2024-03-03T01:03:43.423632Z","iopub.status.idle":"2024-03-03T01:03:43.668736Z","shell.execute_reply.started":"2024-03-03T01:03:43.423601Z","shell.execute_reply":"2024-03-03T01:03:43.667861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And there we have our very own image generator ðŸ¥³. This is a very basic model but these are series of notebooks so we are definetly going to make this better","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\n\nSo the predicted images are very blury but atleast for some the images, you can tell that they are for a human being and the hair color is some what consistent for all the images. The images can still be definelty improved by increasing on the latent space but we don't the model to end up predicting exactly what is in the dataset. <br>\nAnyways this is a start and in the next notebook we will be implementing the famous **VAE** and we see how better it performs compared to the normal auto-encoders.\n\nIf you found this notebook helpful feel free to give me an upvote. otherwise. see you in the next Notebook","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}